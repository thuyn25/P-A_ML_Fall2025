{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1d3c2c",
   "metadata": {},
   "source": [
    "# Introduction to _PyTorch_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b570e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "_*PyTorch*_ is an open-source deep learning framework developed by Facebook's AI Research lab. It provides a flexible and efficient platform for building and training neural networks, supporting dynamic computation graphs and GPU acceleration. PyTorch is widely used in both academia and industry for research and production due to its intuitive interface and strong community support.\n",
    "\n",
    "For more details, visit the [official PyTorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4390e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d1272",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb782d0",
   "metadata": {},
   "source": [
    "In machine learning we will deal with tensors a lot. As a reminder 1-d tensor is a vector (called array in programming jargon); a 2-d tensor is a matrix; if dimentions are k>2 we talk about $k^{th}$-order tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b3c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing the x vector: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print('printing the x vector:', x) \n",
    "# note that in jupyter notebooks, the output of the last line is automatically displayed even without a print statement:\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c20730",
   "metadata": {},
   "source": [
    "### Counting elements, shape and reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9a035",
   "metadata": {},
   "source": [
    "`numel()` returns the total number of elements in the tensor x, regardless of its shape or dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435c36fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454660f",
   "metadata": {},
   "source": [
    "The attribute `x.shape` returns the dimensions (size of each axis) of the tensor x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf8a9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c7148",
   "metadata": {},
   "source": [
    "`x.reshape()` is used to change the shape of the tensor x without changing its data, as long as the total number of elements remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb650be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3, 4) # Reshape to 3 rows and 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3368c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape) #note that this does not change the original tensor! you need to assign it to a new variable or overwrite the original one\n",
    "\n",
    "X = x.reshape(3, 4) # Now x is reshaped\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a93f25",
   "metadata": {},
   "source": [
    "### zeros-, ones- and randn-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf485ec",
   "metadata": {},
   "source": [
    "`torch.zeros()` creates a tensor filled with zeros, of a specified shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abecf51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]),\n",
       " 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.zeros((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with zeros\n",
    "X, len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5023b5",
   "metadata": {},
   "source": [
    "`torch.ones()` creates a tensor filled with ones, with the specified shape, and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1d57bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "torch.ones((2, 3, 4)) # this creates a 3rd order tensor of shape (2, 3, 4) filled with ones\n",
    "\n",
    "# Note: this is an example of how an RGB image can be represented as a 3rd order tensor: (channels, width, height)\n",
    "# In CNN, the input images are typically represented as 4th order tensors: (batch_size, channels, width, height)"
=======
    "torch.ones((2, 3, 4)) # this creates a 3-d tensor of shape (2, 3, 4) filled with ones\n",
    "# rgb image - 3rd order tensor (d, w, h)"
>>>>>>> aa2d481 (8/29 JN1)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531293a",
   "metadata": {},
   "source": [
    "`torch.randn()` creates a tensor filled with random numbers drawn from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a41c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3329,  0.6797,  0.6344, -1.3191],\n",
       "        [-1.3202, -0.0169, -0.4184,  0.7276],\n",
       "        [-0.5967, -0.0456,  0.0849, -0.4253]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4) # this creates a 2nd order tensor (matrix) of shape (3, 4) filled with random numbers from a normal distribution with mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae8ff0",
   "metadata": {},
   "source": [
    "`torch.tensor()` creates a tensor directly from a Python list, tuple, or NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b7ea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 1, 4, 3], \n",
    "              [1, 2, 3, 4], \n",
    "              [4, 3, 2, 1]]).shape # Create a 2nd order tensor (matrix) with specific values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421b615",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "Indexing and slicing in PyTorch work similarly to NumPy, allowing you to extract, modify, or rearrange parts of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1c19d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #we defined X above, so this will show the reshaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afac8583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] # Access the first row of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e7fc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1] # Access the last row of the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4174e7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:3] # Access rows 1 and 2 of the tensor. Note that index 3 is not included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9232967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5., 17.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 17 # Change the value at row 1, column 2 to 17\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791d706",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Now try to overwrite all values in the first 2 rows of the vector to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c87e3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Write your own code to overwrite all values in the first 2 rows of the matrix to 0\n"
=======
    "# Wrtite your own code to overwrite all values in the first 2 rows of the vector to 0\n",
    "X[0] = torch.zeros(4)\n",
    "X[1] = torch.zeros(4)\n",
    "print(X.shape, X)\n",
    "\n"
>>>>>>> aa2d481 (8/29 JN1)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7ab71",
   "metadata": {},
   "source": [
    "### Operation between tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c755c89",
   "metadata": {},
   "source": [
    "Element-wise operations \n",
    "1) thourgh unitary scalar operations \n",
    "2) through binary scalar operations \n",
    "3) through broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66bb00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 2.9810e+03, 8.1031e+03, 2.2026e+04, 5.9874e+04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)    #calculate e^x for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c3102",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Generate 2 arrays, x and y, on length 5 (aka 5 number of elements each); then try the following operations:\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526e2aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) torch.Size([5]) torch.Size([5]) torch.Size([5]) torch.Size([5]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# write your own code here\n",
    "a = torch.randn(5)\n",
    "b = torch.randn(5)\n",
    "plus = torch.add(a, b)\n",
    "sub = torch.subtract(a, b)\n",
    "mult = torch.multiply(a, b)\n",
    "div = torch.divide(a, b)\n",
    "print(plus.shape, sub.shape, mult.shape, div.shape, a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220f1d1",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941216c",
   "metadata": {},
   "source": [
    "Sometimes, you want to di operations with tensors with different shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bedcd0",
   "metadata": {},
   "source": [
    "Under certain conditions, even when shapes differ, we can still perform elementwise binary operations by invoking the broadcasting mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0fe989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3ee49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5]]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6).reshape((3,2))\n",
    "b = torch.arange(6).reshape((2,3))\n",
    "a.shape, b.shape, a, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9b0aa",
   "metadata": {},
   "source": [
    "Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up. Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows before adding them elementwise."
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a * b).shape"
   ]
  },
  {
=======
>>>>>>> a14021c (Almost finish notebook #1)
   "cell_type": "markdown",
   "id": "186ae70e",
   "metadata": {},
   "source": [
    "### Concatenate tensors, logical statements and sum-all-elements operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92959b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[2., 1., 4., 3.],\n",
       "         [1., 2., 3., 4.],\n",
       "         [4., 3., 2., 1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will be very useful when we will build Convolutional Neural Networks (CNNs) later in the course\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4)) # 3X4 MATRIX from 0-11\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) # manual 3x4 matrix\n",
    "\n",
    "X, Y, torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n",
    "# dim = 0 means aligns both matrix in row-by-row order: X.shape and Y.shapes = 3 rows, 4 columns, thus concat(X,Y).shape = 6x4 (6 rows, 4 columns)\n",
    "# dim = 1 means combine two matrices in column-by-column: concat(X,Y).shape = 3x8 matrix (3 rows, 8 columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35b6e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y # Element-wise comparison between tensors -- returns a tensor of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6746f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(66.), tensor([12., 15., 18., 21.]), tensor([ 6., 22., 38.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(), X.sum(dim=0), X.sum(dim=1) # Sum all elements, sum along rows, sum along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e246e",
   "metadata": {},
   "source": [
    "### Saving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6780316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4., 3.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [4., 3., 2., 1.]])\n",
      "before 4453269152\n",
      "after 5669469616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is crucial in machine learning, as models can have millions of parameters, and we need to save memory!\n",
    "before = id(Y) \n",
    "print(Y)\n",
    "print(\"before\", before)\n",
    "Y=Y+X\n",
    "print(\"after\", id(Y))   # everytime redefine a variable, the memory and id of that var change\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce9dfd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z before: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "id(Z): 5990071168\n",
      "Z after: tensor([[ 2.,  3.,  8.,  9.],\n",
      "        [ 9., 12., 15., 18.],\n",
      "        [20., 21., 22., 23.]])\n",
      "id(Z): 5990071168\n"
     ]
    }
   ],
   "source": [
    "Z = torch.zeros_like(Y) #Z is created the same shape as Y with zeros elements\n",
    "print(\"Z before:\", Z)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y    # all elements of Z are the sum of X and Y\n",
    "print(\"Z after:\", Z)\n",
    "print('id(Z):', id(Z))\n",
    "# they have the same memory address, which means Z is replaced in-place reused for optimized memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79074a",
   "metadata": {},
   "source": [
    "### Conversion to Other Python Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1953d",
   "metadata": {},
   "source": [
    "- If two variables share the **same memory**, a change in one affect the other.\n",
    "- Numpy is CPU-only, while PyTorch can handle GPUs and autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eba3050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> [[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]] tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "\n",
      "tensor([[-99.,   1.,   2.,   3.],\n",
      "        [  4.,   5.,   6.,   7.],\n",
      "        [  8.,   9.,  10.,  11.]]) <class 'torch.Tensor'>\n",
      "tensor([[-99.,   1.,   2.,   3.],\n",
      "        [  4.,   5.,   6.,   7.],\n",
      "        [  8.,   9.,  10.,  11.]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# this is how you convert a tensor to a numpy array and back \n",
    "A = X.numpy()   #convert from tensor to numpy \n",
    "B = torch.from_numpy(A) # convert from numpy to tensor\n",
    "print(type(A), type(B), A, B)\n",
    "print()\n",
    "A[0,0] = -99   # modify NumPy array\n",
    "print(X, type(X))       # change is reflected in the tensor\n",
    "print(B, type(B))       # also reflected here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebf4bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[-99.0, 1.0, 2.0, 3.0], [4.0, 5.0, 6.0, 7.0], [8.0, 9.0, 10.0, 11.0]],\n",
       " tensor([[-99.,   1.,   2.,   3.],\n",
       "         [  4.,   5.,   6.,   7.],\n",
       "         [  8.,   9.,  10.,  11.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how you convert a tensor to a Python list (less used, but still useful)\n",
    "X.tolist(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b72f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3, torch.Tensor, torch.Size([1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code snippet is using the PyTorch library to create a tensor `a` with a single element containing the value 3.5. \n",
    "# - `a` is a PyTorch tensor with a single element [3.5].\n",
    "# - `a.item()` returns the value of the tensor as a Python number (in this case, 3.5).\n",
    "# - `float(a)` converts the tensor to a Python float (in this case, 3.5).\n",
    "# - `int(a)` tries to convert the tensor to an integer, but since the tensor contains a float value, it will raise a ValueError.\n",
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a), type(a), a.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d221b4f",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09a1c4",
   "metadata": {},
   "source": [
    "So far, we have been working with synthetic data that arrived in ready-made tensors. \n",
    "\n",
    "However, to apply deep learning in the wild we must extract messy data stored in arbitrary formats, and preprocess it to suit our needs. Fortunately, the pandas library45 can do much of the heavy lifting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89627975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a7ca6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac23a8b",
   "metadata": {},
   "source": [
    "Before proceeding, look for the file that you just created (in the `data` folder that appeared in your repository). Inspect the `house_tiny.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d2d0ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType   Price\n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094a94e",
   "metadata": {},
   "source": [
    "Now, Our first step in processing the dataset is to separate out columns corresponding to input versus target values. \n",
    "We can select columns either by name or via integer-location based indexing (`iloc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1637bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType\n",
      "0       NaN      NaN\n",
      "1       2.0      NaN\n",
      "2       4.0    Slate\n",
      "3       NaN      NaN\n",
      "\n",
      "0    127500\n",
      "1    106000\n",
      "2    178100\n",
      "3    140000\n",
      "Name: Price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "print(inputs)\n",
    "print()\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912d1fc",
   "metadata": {},
   "source": [
    "You might have noticed that pandas replaced all CSV entries with value NA with a spe- cial NaN (not a number) value. This can also happen whenever an entry is empty, e.g., “3„,270000”. These are called missing values and they are the “bed bugs” of data science.\n",
    "\n",
    " missing values might be handled either via \n",
    " - __imputation__ : replaces missing values with estimates of their values \n",
    " - __deletion__  : simply discards either those rows or those columns that contain missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb9dd0",
   "metadata": {},
   "source": [
    "For categorical input fields, we can treat NaN as a category. Since the `RoofType` column takes values `Slate` and `NaN`, pandas can convert this column into two columns `RoofType_Slate` and `RoofType_nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c968aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)  #replacing na as True value for strings\n",
    "# create each column with that category: return 1 or 0\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c837a",
   "metadata": {},
   "source": [
    "For missing numerical values, one common heuristic is to replace the NaN entries with the mean value of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc4ce1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())   #for numerical values\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477dad1b",
   "metadata": {},
   "source": [
    "Now that all the entries in inputs and targets are numerical, we can load them into a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d4d199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors for inputs and targets\n",
    "X = torch.tensor(inputs.to_numpy(dtype=float))  #inputs: numRooms and RoofType\n",
    "y = torch.tensor(targets.to_numpy(dtype=float)) #targets: house prices\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861edd2",
   "metadata": {},
   "source": [
    "Note: Data visualization tools such as seaborn47 , Bokeh48 , or matplotlib49 can help you to manually inspect the data and develop intuitions about the type of problems you may need to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a1860",
   "metadata": {},
   "source": [
    "Try loading datasets, e.g., Abalone from the [UCI Machine Learning Repository](https://archive.ics.uci.edu) and inspect their properties. What fraction of them has missing values? What fraction of the variables is numerical, categorical, or text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d970c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from ucimlrepo) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from ucimlrepo) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/d2l/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "285f6356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadate of abalone\n",
      "{'uci_id': 1, 'name': 'Abalone', 'repository_url': 'https://archive.ics.uci.edu/dataset/1/abalone', 'data_url': 'https://archive.ics.uci.edu/static/public/1/data.csv', 'abstract': 'Predict the age of abalone from physical measurements', 'area': 'Biology', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Tabular'], 'num_instances': 4177, 'num_features': 8, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['Rings'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1994, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C55C7W', 'creators': ['Warwick Nash', 'Tracy Sellers', 'Simon Talbot', 'Andrew Cawthorn', 'Wes Ford'], 'intro_paper': None, 'additional_info': {'summary': 'Predicting the age of abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.\\r\\n\\r\\nFrom the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Given is the attribute name, attribute type, the measurement unit and a brief description.  The number of rings is the value to predict: either as a continuous value or as a classification problem.\\r\\n\\r\\nName / Data Type / Measurement Unit / Description\\r\\n-----------------------------\\r\\nSex / nominal / -- / M, F, and I (infant)\\r\\nLength / continuous / mm / Longest shell measurement\\r\\nDiameter\\t/ continuous / mm / perpendicular to length\\r\\nHeight / continuous / mm / with meat in shell\\r\\nWhole weight / continuous / grams / whole abalone\\r\\nShucked weight / continuous\\t / grams / weight of meat\\r\\nViscera weight / continuous / grams / gut weight (after bleeding)\\r\\nShell weight / continuous / grams / after being dried\\r\\nRings / integer / -- / +1.5 gives the age in years\\r\\n\\r\\nThe readme file contains attribute statistics.', 'citation': None}}\n",
      "variable information\n",
      "             name     role         type demographic  \\\n",
      "0             Sex  Feature  Categorical        None   \n",
      "1          Length  Feature   Continuous        None   \n",
      "2        Diameter  Feature   Continuous        None   \n",
      "3          Height  Feature   Continuous        None   \n",
      "4    Whole_weight  Feature   Continuous        None   \n",
      "5  Shucked_weight  Feature   Continuous        None   \n",
      "6  Viscera_weight  Feature   Continuous        None   \n",
      "7    Shell_weight  Feature   Continuous        None   \n",
      "8           Rings   Target      Integer        None   \n",
      "\n",
      "                   description  units missing_values  \n",
      "0         M, F, and I (infant)   None             no  \n",
      "1    Longest shell measurement     mm             no  \n",
      "2      perpendicular to length     mm             no  \n",
      "3           with meat in shell     mm             no  \n",
      "4                whole abalone  grams             no  \n",
      "5               weight of meat  grams             no  \n",
      "6  gut weight (after bleeding)  grams             no  \n",
      "7            after being dried  grams             no  \n",
      "8  +1.5 gives the age in years   None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "abalone = fetch_ucirepo(id=1) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = abalone.data.features \n",
    "y = abalone.data.targets \n",
    "\n",
    "# metadata\n",
    "print(\"metadate of abalone\") \n",
    "print(abalone.metadata) \n",
    "  \n",
    "# variable information \n",
    "print('variable information')\n",
    "print(abalone.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7cb965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
      "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
      "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
      "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
      "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
      "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
      "...   ..     ...       ...     ...           ...             ...   \n",
      "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
      "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
      "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
      "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
      "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
      "\n",
      "      Viscera_weight  Shell_weight  \n",
      "0             0.1010        0.1500  \n",
      "1             0.0485        0.0700  \n",
      "2             0.1415        0.2100  \n",
      "3             0.1140        0.1550  \n",
      "4             0.0395        0.0550  \n",
      "...              ...           ...  \n",
      "4172          0.2390        0.2490  \n",
      "4173          0.2145        0.2605  \n",
      "4174          0.2875        0.3080  \n",
      "4175          0.2610        0.2960  \n",
      "4176          0.3765        0.4950  \n",
      "\n",
      "[4177 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(X.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06cfcae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  2.,  6.,  6.],\n",
      "        [ 5.,  7.,  9., 11.],\n",
      "        [12., 12., 12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88a52690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(abalone.metadata.has_missing_values)\n",
    "print(abalone.metadata.num_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3151dd7",
   "metadata": {},
   "source": [
    "What fraction of them has missing values? \n",
    "- None of them has missing values\n",
    "\n",
    "What fraction of the variables is numerical, categorical, or text?\n",
    "- One of them is categorical/text\n",
    "- 7 of the features is numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb1db3",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb055ea2",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91496402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.),\n",
       " torch.Size([]),\n",
       " tensor(2.),\n",
       " tensor(5.),\n",
       " tensor(6.),\n",
       " tensor(1.5000),\n",
       " tensor(9.))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "x, (x.shape), y, x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d72ef",
   "metadata": {},
   "source": [
    "### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69b99bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor(0), tensor(1), tensor(2))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that python has a zero-based indexing, so the first element is at index 0\n",
    "x = torch.arange(3)\n",
    "x, x[0], x[1], x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "136fe762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, int)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), type(len(x)) # Count the number of elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0edaef07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, type(x.shape) # Get the shape of the tensor. Note this is a different type the the output of `len(x)`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d099a",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ffcddd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e228ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T # Transpose the matrix A. Symmetric matrices are the subset of square matrices that are equal to their own transposes\n",
    "# A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551e81d",
   "metadata": {},
   "source": [
    "### Tensors and tensor aritmethic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1392125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.arange(24).reshape(2, 3, 4)\n",
    "W\n",
    "# 2 matrices, each matrix is a 3x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a34227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = A.clone()  # Assign a copy of A to B by allocating new memory\n",
    "A, A + B # Element-wise addition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f114b",
   "metadata": {},
   "source": [
    "### Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aebccc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B # Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd27dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " tensor([[[ 0,  2,  4,  6],\n",
       "          [ 8, 10, 12, 14],\n",
       "          [16, 18, 20, 22]],\n",
       " \n",
       "         [[24, 26, 28, 30],\n",
       "          [32, 34, 36, 38],\n",
       "          [40, 42, 44, 46]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4) \n",
    "X, a + X, a * X, (a * X).shape # addition and multiplication with a scalar, and the shape of the resulting tensor (unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d0cf7",
   "metadata": {},
   "source": [
    "* multiply a tensor matrix with a scalar does not change shape of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529b89f",
   "metadata": {},
   "source": [
    "### Sums of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f0eaafc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor(15.),\n",
       " tensor([3., 5., 7.]),\n",
       " tensor([ 3., 12.]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of elements in a tensor\n",
    "A, A.sum(), A.sum(dim=0), A.sum(dim=1) # Sum all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c900610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1]) == A.sum() # Same as A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac0833f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.5000), tensor(2.5000))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel() # Mean and average of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89c6b06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0] # Mean and average of elements in a tensor along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b005c6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]]) torch.Size([2, 3])\n",
      "tensor([[ 3.],\n",
      "        [12.]]) torch.Size([2, 1])\n",
      "tensor([ 3., 12.]) torch.Size([2])\n",
      "tensor([[3., 5., 7.]]) torch.Size([1, 3])\n",
      "tensor([3., 5., 7.]) torch.Size([3])\n",
      "tensor([[ 3.],\n",
      "        [12.]]) torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Sometimes it can be useful to keep the number of axes unchanged when invoking the function for calculating the sum or mean. \n",
    "# This matters when we want to use the broadcast mechanism.\n",
    "\n",
    "# sum_A = A.sum(axis=0, keepdims=True)    #sum of each column of A -> 1x3 matrix\n",
    "# This line of code is calculating the sum of each row of the array `A` and keeping the number of axes unchanged by setting `keepdims=True`. The result is stored in the variable `sum_A`, which will be a 2x1 matrix where each element represents the sum of the corresponding row in the original array `A`.\n",
    "sum_A = A.sum(axis=1, keepdims=True)    #sum of each row of A -> 2x1 matrix\n",
    "sum_B = A.sum(axis=1, keepdims=False)    #sum of each row of A -> 2x1 matrix\n",
    "print(A, A.shape)\n",
    "print(sum_A, sum_A.shape)    # result: 2-elements matrix\n",
    "print(sum_B, sum_B.shape)    # result: 2x1 matrix\n",
    "sum_C = A.sum(axis=0, keepdims=True)    #sum of each column of A -> 1x3 matrix\n",
    "sum_D = A.sum(axis=0, keepdims=False)    #sum of each colum of A -> 1x3 matrix\n",
    "# print(A.sum(axis=0), A.sum(axis=0).shape)   #summing the columns -> 1x3 matrix\n",
    "print(sum_C, sum_C.shape)    # result: 3-elements matrix\n",
    "print(sum_D, sum_D.shape)    # result: 1x3 matrix\n",
    "\n",
    "print(sum_A, sum_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6d12f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([[ 3.],\n",
      "        [12.]])\n",
      "tensor([[0.0000, 0.3333, 0.6667],\n",
      "        [0.2500, 0.3333, 0.4167]])\n"
     ]
    }
   ],
   "source": [
    "# since sum_A keeps its two axes after summing each row, \n",
    "# we can divide A by sum_A with broadcasting to create a matrix where each row sums up to 1.\n",
    "# this is a common technique for normalizing data, expecially for classification tasks, in which\n",
    "# we want to ensure that the sum of probabilities across each row is 1.\n",
    "print(A)\n",
    "print(sum_A)\n",
    "print(A / sum_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b08122f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  3.],\n",
       "        [ 3.,  7., 12.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to calculate the cumulative sum of elements of A along some axis, say axis=0, \n",
    "# we can call the cumsum function.\n",
    "# A.cumsum(axis=0)\n",
    "A.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346737f",
   "metadata": {},
   "source": [
    "adding sum of previous elements to the current elements (in column axis=0 OR in row axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ac330",
   "metadata": {},
   "source": [
    "### Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f057dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cumulative sum along the specified dimension\n",
    "cumulative_sum_axis0 = torch.cumsum(A, dim=0)\n",
    "cumulative_sum_axis1 = torch.cumsum(A, dim=1)\n",
    "\n",
    "print(A)\n",
    "print(cumulative_sum_axis0)\n",
    "print(cumulative_sum_axis1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff4a7f",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cba9532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.), tensor(3.))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product of two vectors\n",
    "x = torch.arange(3, dtype = torch.float32)\n",
    "y = torch.ones(3, dtype = torch.float32)\n",
<<<<<<< HEAD
    "print(x, y, torch.dot(x, y))\n",
    "# or equivalently\n",
    "print(torch.sum(x * y)) # Element-wise multiplication followed by summation"
=======
    "# x, y, torch.dot(x, y)\n",
    "# or equivalently\n",
    "x, y, torch.dot(x, y), torch.sum(x * y) # Element-wise multiplication followed by summation"
>>>>>>> a14021c (Almost finish notebook #1)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a5092",
   "metadata": {},
   "source": [
    "### Matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "50616410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]]) torch.Size([2, 3])\n",
      "x:  tensor([0., 1., 2.]) torch.Size([3])\n",
      "torch.mv(A, x): tensor([ 5., 14.])\n",
      "tensor([ 5., 14.]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix-vector multiplication -- this is a common operation in machine learning, especially in linear layers\n",
    "print(\"A: \", A, A.shape)    # A = matrix\n",
    "print(\"x: \", x, x.shape)    # x = vector\n",
    "# The line `print(\"torch.mv(A, x):\", torch.mv(A, x))` is calculating the matrix-vector multiplication of matrix `A` and vector `x` using PyTorch's `torch.mv` function. This operation multiplies a matrix by a vector to produce a new vector. The result is then printed out along with the message \"torch.mv(A, x):\".\n",
    "print(\"torch.mv(A, x):\", torch.mv(A, x))    \n",
    "print(A@x, (A@x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69531c9",
   "metadata": {},
   "source": [
    "### Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e1168ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix-matrix multiplication\n",
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
    "B = torch.ones(3, 4)\n",
    "A, B, torch.mm(A, B), A@B   #result = 2x4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b804e7b",
   "metadata": {},
   "source": [
    "#### torch.mm VS '@'\n",
    "\n",
    "Applied to matrices the two operation are exactly the same. \n",
    "\n",
    "\"@\" calls in the back end `torch.matmul()`\n",
    "\n",
    "#### Key difference:\n",
    "- `torch.mm`: strictly 2D matrices only.\n",
    "- `@` (→ `torch.matmul`): much more flexible, supports batched and vector × matrix cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b8794",
   "metadata": {},
   "source": [
    "### Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d5f53",
   "metadata": {},
   "source": [
    "#### l2 norm (Euclidean norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cb5ef",
   "metadata": {},
   "source": [
    "$|u| = \\sqrt{\\sum{|u_i|^2}}\n",
    "    = \\sqrt{3^2 + 4^2} = \\sqrt{9+16} = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f11c3382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)\n",
    "# |u| = \\sqrt(sum of |u_i|^2) \n",
    "#       = \\sqrt(3^2 + 4^2) = \\sqrt(9+16) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2e05ece5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(u * u).sum().sqrt()  # same as torch.norm func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac97e0",
   "metadata": {},
   "source": [
    "#### l1 norm (Manhattan distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f693b",
   "metadata": {},
   "source": [
    "$|u| = \\sum{|u_i|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9214a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()\n",
    "# |u| = sum of |u_i|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1ff0b",
   "metadata": {},
   "source": [
    "#### Frobenius norm (l2 norm for matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "019166c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]),\n",
       " tensor(4.4721))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D = torch.ones((4, 9))\n",
    "D = torch.ones((4, 5))\n",
    "D, torch.norm(D)\n",
    "# ||D|| = \\sqrt(sum of sum of |D_ij|^2) -> for mxn matrix\n",
    "#       = \\sqrt(20) = 4.4724\n",
    "# torch.norm(D)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beb08d",
   "metadata": {},
   "source": [
    "-------------------- *YOUR TURN*!!! ----------------\n",
    "\n",
    "Define a vector x of values ranging between -5 and 5. Plot the x^2 and |x|. \n",
    "\n",
    "Looking at the plot, think about what is the effect of l2 and l1 norms of different vectors, how do their norms compare if both are computed as l2 or as l1?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "733ec168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.0000, -5.9900, -5.9800,  ...,  5.9700,  5.9800,  5.9900])\n",
      "tensor([36.0000, 35.8801, 35.7604,  ..., 35.6409, 35.7604, 35.8801])\n",
      "L1 norm:  tensor(3600.)\n",
      "L2 norm:  tensor(120.0001)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write you code here. To plotting you can use the python library matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def x_squared(x):\n",
    "    return x * x\n",
    "\n",
    "def abs_x(x):\n",
    "    return abs(x)\n",
    "\n",
    "def l1_norm(x):\n",
    "    return torch.abs(x).sum()\n",
    "\n",
    "def l2_norm(x):\n",
    "    return (x * x).sum().sqrt()\n",
    "\n",
    "x = torch.arange(-6,6, step=0.01, dtype=torch.float32)\n",
    "print(x)\n",
    "print(x_squared(x))\n",
    "print(\"L1 norm: \", l1_norm(x))\n",
    "print(\"L2 norm: \",l2_norm(x))\n",
    "# ...code for plotting...\n",
    "plt.plot(x, x_squared(x), color='k', label=r\"L2\")\n",
    "plt.plot(x, abs_x(x), color='r', label=r\"L1\")\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c39ab5",
   "metadata": {},
   "source": [
    "why are there 2 different norms with the same tensor?\n",
    "\n",
    "regularization term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19eb78d",
   "metadata": {},
   "source": [
    "There are more norm formula:\n",
    "\n",
    "$l_p$ norm: $|l|_p = \\sqrt{\\sum{x_i^p}}$\n",
    "\n",
    "* maxinum value of the matrix: max(W)\n",
    "\n",
    "**Forbenius norm**\n",
    "$|| X||_F = \\sum{\\sum{x_{ij}^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04899b9e",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefb75b",
   "metadata": {},
   "source": [
    "Use your coding skills to di the following exercizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01407ba",
   "metadata": {},
   "source": [
    "### Ex. 1 -- Prove that the transpose of the transpose of a matrix is the matrix itself \n",
    "\n",
    "$(A^⊤)^⊤ = A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b066fd",
   "metadata": {},
   "source": [
    "**Solution: the proof**\n",
    "\n",
    "$(A^T)_{ij} = A_{ji}. \\text{ Thus, } ((A^T)^T)_{ij} = (A^T)_{ji} = A_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0e6428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  tensor([[ 1.7234,  0.9046, -0.8749, -1.4693, -0.0901],\n",
      "        [ 0.4291, -2.2888, -0.1390,  0.5486,  1.0686],\n",
      "        [ 0.6733, -0.1615,  1.6259,  0.4077,  0.4980]])\n",
      "A_TT:  tensor([[ 1.7234,  0.9046, -0.8749, -1.4693, -0.0901],\n",
      "        [ 0.4291, -2.2888, -0.1390,  0.5486,  1.0686],\n",
      "        [ 0.6733, -0.1615,  1.6259,  0.4077,  0.4980]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3, 5)\n",
    "print(\"A: \", A)\n",
    "A_TT = A.T.T    #transpose (A^T)^T\n",
    "print(r\"A_TT: \", A_TT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f05cea",
   "metadata": {},
   "source": [
    "### Ex. 2 -- Given two matrices A and B, show that sum and transposition commute: \n",
    "\n",
    "$A^⊤ + B^⊤ = (A + B)^⊤$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca853edb",
   "metadata": {},
   "source": [
    "**Solution: the proof**\n",
    "\n",
    "$A^T + B^T = (A^T)_{ij}+(B^T)_{ij} = A_{ji} + B_{ji} = (A+B)_{ji}$\n",
    "\n",
    "While,\n",
    "$(A+B)^T = ((A+B)^T)_{ij} = (A+B)_{ji}$.\n",
    "\n",
    "Therefore, $A^T + B^T = (A+B)^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e6343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(2,3)\n",
    "B = torch.randn(2,3)\n",
    "LHS = A.T + B.T\n",
    "RHS = (A+B).T \n",
    "print(LHS == RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb648b",
   "metadata": {},
   "source": [
    "### Ex. 3 -- We defined the tensor X of shape (2, 3, 4) in this section. What is the output of len(X)? Write your answer without implementing any code, then check your answer using code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9fca7b",
   "metadata": {},
   "source": [
    "**Pre-code Answer:** the output of len(X) is $2*3*4 = 24$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd338531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " 2,\n",
       " torch.Size([2, 3, 4]),\n",
       " 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4) \n",
    "X, len(X), X.shape, X.numel()\n",
    "# len(X) gives the size of the first dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af372d",
   "metadata": {},
   "source": [
    "### Ex 4 -- Consider three matrices, say A, B, C ∈ R100×200. Construct a tensor with three axes by stacking [A, B, C]. What is the dimensionality? Slice out the second coordinate of the third axis to recover B. Check that your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97833eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3911, -0.3113, -0.2673,  ...,  0.4425, -1.9716, -0.3210],\n",
      "         [ 0.1925, -1.1044,  1.5331,  ...,  0.2560,  0.4652,  0.8413],\n",
      "         [-1.0385, -1.5510, -0.0301,  ...,  0.1687, -1.1381, -1.9579],\n",
      "         ...,\n",
      "         [-0.3647,  0.4809, -0.4489,  ...,  0.0264,  0.8260, -1.7324],\n",
      "         [ 0.7114, -2.0592,  0.3386,  ..., -0.8047,  0.9332, -0.0325],\n",
      "         [ 0.1982, -0.7048, -0.4702,  ...,  0.7193, -0.1704, -0.0933]],\n",
      "\n",
      "        [[ 0.2530,  0.0892, -0.9127,  ...,  0.1913, -0.6822, -0.8245],\n",
      "         [-1.8255,  0.2457, -1.2809,  ...,  0.4191, -0.1633,  0.3376],\n",
      "         [-0.7220, -1.4591,  0.4976,  ..., -1.8190,  0.8467,  1.3115],\n",
      "         ...,\n",
      "         [-0.5863,  0.6353,  0.8160,  ...,  1.3117, -0.5690, -0.6414],\n",
      "         [ 1.1664,  0.0546,  1.5543,  ..., -0.4958,  0.6794,  1.2906],\n",
      "         [-0.0615,  0.1920,  1.4034,  ..., -0.5725,  0.2909,  0.6851]],\n",
      "\n",
      "        [[ 0.7385,  0.3632,  1.8137,  ...,  0.7900, -0.4545, -0.1569],\n",
      "         [-1.1812, -0.4886,  0.3895,  ..., -1.0420,  0.9885,  0.6235],\n",
      "         [ 0.6023,  1.3879, -1.1872,  ..., -1.0140, -0.3719,  0.4608],\n",
      "         ...,\n",
      "         [ 1.0887,  1.1724, -1.1017,  ...,  2.2109, -0.1742, -0.4196],\n",
      "         [ 0.1229, -1.8042,  3.4172,  ...,  0.3558, -0.3568, -2.3088],\n",
      "         [-0.3452,  0.3585,  1.1051,  ..., -0.3100, -0.6343, -2.1964]]])\n",
      "torch.Size([3, 100, 200])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(100,200)\n",
    "B = torch.randn(100,200)\n",
    "C = torch.randn(100,200)\n",
    "# A, A.shape,B, B.shape, C, C.shape, torch.cat((A,B,C), dim=0),torch.cat((A,B,C), dim=1)\n",
    "ABC = torch.stack((A,B,C))\n",
    "print(ABC)\n",
    "print(ABC.shape)\n",
    "B_recovered = ABC[1,:,:]\n",
    "print(torch.equal(B, B_recovered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b118add",
   "metadata": {},
   "source": [
    "### Ex 5 -- Consider three large matrices, say A ∈ R210 ×216 , B ∈ R216 ×25 and C ∈ R25 ×214 , initialized with Gaussian random variables. You want to compute the product ABC. Is there any difference in memory footprint and speed, depending on whether you compute (AB)C or A(BC). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4687a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint of the product (AB)C\n",
      "Current memory usage: 0.00103 MB\n",
      "Peak memory usage: 0.01115 MB\n",
      "\n",
      "Memory footprint of the product A(BC)\n",
      "Current memory usage: 0.00190 MB\n",
      "Peak memory usage: 0.01202 MB\n"
     ]
    }
   ],
   "source": [
    "A  = torch.randn(210,216)\n",
    "B  = torch.randn(216,25)\n",
    "C  = torch.randn(25,214)\n",
    "\n",
    "import tracemalloc\n",
    "\n",
    "# Memory footprint of the product (AB)C\n",
    "tracemalloc.start()\n",
    "AB = torch.mm(A, B)\n",
    "ABC = torch.mm(AB, C)\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(\"Memory footprint of the product (AB)C\")\n",
    "print(f\"Current memory usage: {current / (1024 * 1024):.5f} MB\")\n",
    "print(f\"Peak memory usage: {peak / (1024 * 1024):.5f} MB\")\n",
    "tracemalloc.stop()\n",
    "\n",
    "# Memory footprint of the product A(BC)\n",
    "print()\n",
    "print(\"Memory footprint of the product A(BC)\")\n",
    "tracemalloc.start()\n",
    "BC = torch.mm(B, C)\n",
    "ABC_alt = torch.mm(A, BC)\n",
    "current2, peak2 = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage: {current2 / (1024 * 1024):.5f} MB\")\n",
    "print(f\"Peak memory usage: {peak2 / (1024 * 1024):.5f} MB\")\n",
    "tracemalloc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574bc5a",
   "metadata": {},
   "source": [
    "**Question:**  Is there any difference in memory footprint and speed, depending on whether you compute (AB)C or A(BC). Why?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "There is not a significant difference in memory footprint and speed between (AB)C and A(BC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ad8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
